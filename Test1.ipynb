{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwZGW/1QCxWl9YVMAHwGr9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmithra29/KindergartenML/blob/main/Test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VU4toSMwgVBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy supervision ultralytics torch opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6MMym3Cu0BE",
        "outputId": "f42ef493-e1df-483f-8642-9a31014046d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting supervision\n",
            "  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.83-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (3.10.0)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.11/dist-packages (from supervision) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (2.32.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (4.67.1)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
            "Downloading supervision-0.25.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.83-py3-none-any.whl (922 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.2/922.2 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, supervision, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 supervision-0.25.1 ultralytics-8.3.83 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8m-pose.pt\")\n",
        "edge_annotator = sv.EdgeAnnotator()\n",
        "vertex_annotator = sv.VertexAnnotator()\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "tracker = sv.ByteTrack()\n",
        "smoother = sv.DetectionsSmoother()\n",
        "trace_annotator = sv.TraceAnnotator()\n",
        "\n",
        "def callback(frame: np.ndarray, _: int) -> np.ndarray:\n",
        "    results = model(frame)[0]\n",
        "    key_points = sv.KeyPoints.from_ultralytics(results)\n",
        "    detections = key_points.as_detections()\n",
        "    detections = tracker.update_with_detections(detections)\n",
        "    detections = smoother.update_with_detections(detections)\n",
        "\n",
        "    annotated_frame = edge_annotator.annotate(\n",
        "        frame.copy(), key_points=key_points)\n",
        "    annotated_frame = vertex_annotator.annotate(\n",
        "        annotated_frame, key_points=key_points)\n",
        "    annotated_frame = box_annotator.annotate(\n",
        "        annotated_frame, detections=detections)\n",
        "    return trace_annotator.annotate(\n",
        "        annotated_frame, detections=detections)\n",
        "\n",
        "sv.process_video(\n",
        "    source_path=\"people-walking.mp4\",\n",
        "    target_path=\"result.mp4\",\n",
        "    callback=callback\n",
        ")"
      ],
      "metadata": {
        "id": "YYY4SM8Xq2m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd2da72-f7f9-4041-a459-60d2c1244db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 72.6ms\n",
            "Speed: 20.0ms preprocess, 72.6ms inference, 325.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 29.7ms\n",
            "Speed: 3.6ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 4.1ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 5.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 4.2ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 5.8ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 7.6ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.3ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 28.8ms\n",
            "Speed: 12.9ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 9.1ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 5.8ms preprocess, 26.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 27.1ms\n",
            "Speed: 5.6ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.4ms\n",
            "Speed: 3.6ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.0ms\n",
            "Speed: 3.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.3ms\n",
            "Speed: 5.9ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 25.9ms\n",
            "Speed: 3.7ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 25.9ms\n",
            "Speed: 3.6ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 25.9ms\n",
            "Speed: 4.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 25.9ms\n",
            "Speed: 3.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 25.9ms\n",
            "Speed: 3.6ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 25.9ms\n",
            "Speed: 3.5ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 25.9ms\n",
            "Speed: 4.0ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.0ms\n",
            "Speed: 3.8ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 25.9ms\n",
            "Speed: 3.9ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.0ms\n",
            "Speed: 3.6ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 25.9ms\n",
            "Speed: 3.5ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 4.3ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 6.6ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.4ms\n",
            "Speed: 5.8ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.0ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 6.2ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 27.0ms\n",
            "Speed: 4.6ms preprocess, 27.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 29.9ms\n",
            "Speed: 3.6ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 29.0ms\n",
            "Speed: 8.5ms preprocess, 29.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 29.7ms\n",
            "Speed: 3.4ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 38.6ms\n",
            "Speed: 3.5ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 43.1ms\n",
            "Speed: 3.5ms preprocess, 43.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 69.6ms\n",
            "Speed: 3.9ms preprocess, 69.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 35.5ms\n",
            "Speed: 11.7ms preprocess, 35.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 13.5ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 48.8ms\n",
            "Speed: 4.6ms preprocess, 48.8ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 62.5ms\n",
            "Speed: 3.6ms preprocess, 62.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 39.4ms\n",
            "Speed: 8.6ms preprocess, 39.4ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 28.8ms\n",
            "Speed: 4.0ms preprocess, 28.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 31.2ms\n",
            "Speed: 3.7ms preprocess, 31.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 31.5ms\n",
            "Speed: 3.4ms preprocess, 31.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 27.2ms\n",
            "Speed: 3.4ms preprocess, 27.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 28.0ms\n",
            "Speed: 3.4ms preprocess, 28.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 48.3ms\n",
            "Speed: 11.9ms preprocess, 48.3ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 32.7ms\n",
            "Speed: 14.0ms preprocess, 32.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 34.1ms\n",
            "Speed: 3.8ms preprocess, 34.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 34.5ms\n",
            "Speed: 15.6ms preprocess, 34.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 32.9ms\n",
            "Speed: 7.3ms preprocess, 32.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 32.8ms\n",
            "Speed: 3.5ms preprocess, 32.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 30.5ms\n",
            "Speed: 11.7ms preprocess, 30.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 30.4ms\n",
            "Speed: 3.7ms preprocess, 30.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 31.0ms\n",
            "Speed: 3.6ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 27.8ms\n",
            "Speed: 4.0ms preprocess, 27.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 28.3ms\n",
            "Speed: 9.6ms preprocess, 28.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 27.2ms\n",
            "Speed: 3.9ms preprocess, 27.2ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 39.4ms\n",
            "Speed: 3.5ms preprocess, 39.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 29.0ms\n",
            "Speed: 3.5ms preprocess, 29.0ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 7.0ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 6.5ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 28.5ms\n",
            "Speed: 8.8ms preprocess, 28.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 4.1ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 32.6ms\n",
            "Speed: 3.3ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 27.0ms\n",
            "Speed: 3.6ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 4.7ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 5.2ms preprocess, 26.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 28.7ms\n",
            "Speed: 3.4ms preprocess, 28.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 31.2ms\n",
            "Speed: 3.5ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 7.6ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 8.5ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 29.8ms\n",
            "Speed: 3.4ms preprocess, 29.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 27.6ms\n",
            "Speed: 5.5ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 8.7ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 6.2ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 27.5ms\n",
            "Speed: 5.3ms preprocess, 27.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 4.1ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.assets import download_assets, VideoAssets\n",
        "\n",
        "download_assets(VideoAssets.PEOPLE_WALKING)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8kIZywowCgC-",
        "outputId": "1311d4e7-66f4-42c3-eac2-385810886cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "people-walking.mp4 asset download complete. \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'people-walking.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "source": [
        "!nvidia-smi"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vCa2dMYgg1G",
        "outputId": "49324ead-136c-41af-8ce9-cd33f1be01f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 22 05:03:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **px/s**"
      ],
      "metadata": {
        "id": "kKpS_vgRbxDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(\"yolov8m-pose.pt\")\n",
        "\n",
        "# Initialize annotators\n",
        "edge_annotator = sv.EdgeAnnotator()\n",
        "vertex_annotator = sv.VertexAnnotator()\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "trace_annotator = sv.TraceAnnotator()\n",
        "\n",
        "# Initialize tracker and smoother\n",
        "tracker = sv.ByteTrack()\n",
        "smoother = sv.DetectionsSmoother()\n",
        "\n",
        "# Dictionary to store previous positions of tracked objects\n",
        "previous_positions = {}\n",
        "\n",
        "# Get video properties (FPS)\n",
        "cap = cv2.VideoCapture(\"people-walking.mp4\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "cap.release()\n",
        "\n",
        "# Calibration factor (pixels per meter) - Adjust this based on your video!\n",
        "PIXELS_PER_METER = 100  # Example: 100 pixels = 1 meter\n",
        "\n",
        "def calculate_speed(current_pos, prev_pos, fps, pixels_per_meter):\n",
        "    \"\"\"Calculate speed in meters per second.\"\"\"\n",
        "    distance_pixels = np.linalg.norm(current_pos - prev_pos)  # Euclidean distance in pixels\n",
        "    distance_meters = distance_pixels / pixels_per_meter  # Convert to meters\n",
        "    time_interval = 1 / fps  # Time between frames in seconds\n",
        "    speed = distance_meters / time_interval  # Speed in meters/second\n",
        "    return speed\n",
        "\n",
        "def callback(frame: np.ndarray, frame_idx: int) -> np.ndarray:\n",
        "    # Run YOLO model and get key points\n",
        "    results = model(frame)[0]\n",
        "    key_points = sv.KeyPoints.from_ultralytics(results)\n",
        "    detections = key_points.as_detections()\n",
        "\n",
        "    # Update tracker and smoother\n",
        "    detections = tracker.update_with_detections(detections)\n",
        "    detections = smoother.update_with_detections(detections)\n",
        "\n",
        "    # Debug: Check the type and content of detections\n",
        "    print(f\"Frame {frame_idx}: detections type = {type(detections)}\")\n",
        "    if hasattr(detections, 'tracker_id'):\n",
        "        print(f\"Tracker IDs: {detections.tracker_id}\")\n",
        "    else:\n",
        "        print(\"No tracker_id attribute found in detections\")\n",
        "\n",
        "    # Annotate frame\n",
        "    annotated_frame = edge_annotator.annotate(frame.copy(), key_points=key_points)\n",
        "    annotated_frame = vertex_annotator.annotate(annotated_frame, key_points=key_points)\n",
        "    annotated_frame = box_annotator.annotate(annotated_frame, detections=detections)\n",
        "\n",
        "    # Process detections if they have tracker_id\n",
        "    if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n",
        "        for i in range(len(detections.tracker_id)):\n",
        "            track_id = detections.tracker_id[i]\n",
        "            if track_id is None:\n",
        "                continue\n",
        "\n",
        "            # Get the centroid of the bounding box (x, y)\n",
        "            x1, y1, x2, y2 = detections.xyxy[i]\n",
        "            current_pos = np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n",
        "\n",
        "            if track_id in previous_positions and frame_idx > 0:\n",
        "                prev_pos = previous_positions[track_id]\n",
        "                speed = calculate_speed(current_pos, prev_pos, fps, PIXELS_PER_METER)\n",
        "\n",
        "                # Annotate speed on the frame (in meters/second)\n",
        "                label = f\"ID {track_id}: {speed:.2f} m/s\"\n",
        "                cv2.putText(\n",
        "                    annotated_frame,\n",
        "                    label,\n",
        "                    (int(x1), int(y1) - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5,\n",
        "                    (0, 255, 0),\n",
        "                    2,\n",
        "                )\n",
        "\n",
        "            # Update previous position\n",
        "            previous_positions[track_id] = current_pos\n",
        "    else:\n",
        "        print(\"Skipping speed calculation due to missing tracker_id\")\n",
        "\n",
        "    return trace_annotator.annotate(annotated_frame, detections=detections)\n",
        "\n",
        "# Process the video\n",
        "sv.process_video(\n",
        "    source_path=\"people-walking.mp4\",\n",
        "    target_path=\"result.mp4\",\n",
        "    callback=callback\n",
        ")"
      ],
      "metadata": {
        "id": "G08WIzPBCjjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468cacc6-966c-47e5-b7a4-ecb411b6ae32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 27.4ms\n",
            "Speed: 2.6ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 0: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 2: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 3: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 4: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 5: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 6: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12 18]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 7: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12 18]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 8: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 9: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 10: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 5.2ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 11: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 12: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 13: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 14: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 15: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 16: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10  9]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 17: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10  9]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 18: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10  9]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 19: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 20: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 21: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 22: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 23: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 24: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 25: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 26: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 27: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 5.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 28: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 29: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 30: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 31: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 32: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 33: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 34: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 27.4ms\n",
            "Speed: 4.7ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 35: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 36: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 37: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 38: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 39: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 40: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 41: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 42: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.8ms\n",
            "Speed: 3.5ms preprocess, 26.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 43: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 44: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 45: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 15 persons, 26.7ms\n",
            "Speed: 4.4ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 46: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 47: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 48: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 49: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 50: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 51: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 52: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 53: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 54: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31]\n",
            "\n",
            "0: 384x640 19 persons, 26.7ms\n",
            "Speed: 3.7ms preprocess, 26.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 55: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 56: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32 33]\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 4.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 57: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32 33]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 58: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32 33]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 59: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32 33]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 60: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 23 32 33]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 61: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21 29 23 32 33]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 62: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 23 32 33]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 63: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 23 32 33]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 64: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 23 32]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 5.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 65: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 66: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35 36 33 23]\n",
            "\n",
            "0: 384x640 18 persons, 30.9ms\n",
            "Speed: 11.9ms preprocess, 30.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 67: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 68: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 29.4ms\n",
            "Speed: 3.5ms preprocess, 29.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 69: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35 36 33 23]\n",
            "\n",
            "0: 384x640 19 persons, 26.8ms\n",
            "Speed: 3.8ms preprocess, 26.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 70: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 71: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 72: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 73: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 16 persons, 29.2ms\n",
            "Speed: 3.9ms preprocess, 29.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 74: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 6.9ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 75: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 43 42]\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 76: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 43 42 23 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 77: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 23 44]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 78: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 23 44]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 79: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 23 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 6.9ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 80: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 23 44 31]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 81: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31]\n",
            "\n",
            "0: 384x640 18 persons, 27.1ms\n",
            "Speed: 3.4ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 82: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46]\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 83: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 84: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46]\n",
            "\n",
            "0: 384x640 17 persons, 29.9ms\n",
            "Speed: 3.7ms preprocess, 29.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 85: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46]\n",
            "\n",
            "0: 384x640 18 persons, 27.1ms\n",
            "Speed: 3.5ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 86: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46 33]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 87: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46 33]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 88: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 89: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 90: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 91: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 92: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 93: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 94: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 95: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 96: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 97: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.8ms\n",
            "Speed: 3.8ms preprocess, 26.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 98: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 99: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 100: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 101: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 102: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 103: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 104: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 105: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 5.2ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 106: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 107: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 108: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 109: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 110: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 111: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 16 persons, 27.3ms\n",
            "Speed: 3.2ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 112: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 113: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 114: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 115: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 116: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 4.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 117: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 118: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 119: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 120: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 121: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 122: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 123: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 32 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 124: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 32 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 125: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 32 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 126: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 127: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 128: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 129: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 130: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 131: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 132: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 5.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 133: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 134: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 135: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 136: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 137: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 138: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 139: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 18 21 29 43 42 46 33 44 56 32]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 140: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 18 21 29 43 42 46 33 44 56 32]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 141: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 18 21 29 43 42 46 33 44 56 32  3]\n",
            "\n",
            "0: 384x640 8 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 142: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 32  3]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 143: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 32  3 18]\n",
            "\n",
            "0: 384x640 8 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 144: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 32  3 18]\n",
            "\n",
            "0: 384x640 11 persons, 26.6ms\n",
            "Speed: 4.2ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 145: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56  3 18]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 146: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 147: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 148: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 149: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 150: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 151: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 152: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 153: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 154: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 155: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 10 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 156: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 5.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 157: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 158: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 159: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44 58 59]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 160: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 161: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59 44]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 162: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 163: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 164: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59 44]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 165: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44 61]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 166: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44 61 59]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 2.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 167: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 168: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 169: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59 44]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 170: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 171: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 172: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 173: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 174: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 175: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 176: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 6.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 177: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 178: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 179: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 4.8ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 180: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 181: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 58]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 182: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 58]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 183: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 58]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 184: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 6.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 185: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 186: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 187: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 188: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 189: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 190: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 191: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 192: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 193: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 194: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 195: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 196: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 197: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 6.0ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 198: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 5.2ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 199: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 200: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 5.6ms preprocess, 26.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 201: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 202: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 203: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 204: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 205: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.8ms\n",
            "Speed: 3.7ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 206: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 207: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 208: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 29.5ms\n",
            "Speed: 4.1ms preprocess, 29.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 209: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 210: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 211: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 16 persons, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 212: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 213: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 214: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 215: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 29.9ms\n",
            "Speed: 3.4ms preprocess, 29.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 216: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 7.2ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 217: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 17 persons, 27.4ms\n",
            "Speed: 5.6ms preprocess, 27.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 218: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 7.1ms preprocess, 26.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 219: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 15 persons, 28.9ms\n",
            "Speed: 3.8ms preprocess, 28.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 220: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 221: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 222: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 223: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.7ms\n",
            "Speed: 3.7ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 224: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 225: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 226: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 227: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 228: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.9ms\n",
            "Speed: 3.5ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 229: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 230: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 4.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 231: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 232: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 233: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 234: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 235: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 236: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 237: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 238: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75 82]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 239: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 27.4ms\n",
            "Speed: 3.4ms preprocess, 27.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 240: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 241: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 242: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 243: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 244: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 245: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 246: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 247: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 248: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 30.5ms\n",
            "Speed: 10.2ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 249: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 82]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 250: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 82 85]\n",
            "\n",
            "0: 384x640 14 persons, 27.8ms\n",
            "Speed: 5.4ms preprocess, 27.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 251: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 85]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 4.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 252: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 85]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 253: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 85]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 254: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 85 88]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 255: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 256: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 257: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 258: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 259: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 260: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 261: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 5.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 262: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 263: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43 89]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 264: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 265: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 266: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 267: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 61 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 268: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 61 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 269: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 61 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.7ms\n",
            "Speed: 5.3ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 270: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 61 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 271: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 272: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 5.8ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 273: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 274: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 275: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 4.9ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 276: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 277: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 278: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 279: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 280: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 6.3ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 281: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 5.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 282: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92 94]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 283: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 284: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 285: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 286: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 287: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 288: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 289: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 290: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 291: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 292: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 293: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 294: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 295: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 296: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 297: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 298: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 299: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94 99]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 300: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  44  62  59  68  70  58  75  88  89  94  99 101]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 4.9ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 301: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  44  62  59  68  70  58  75  88  89  94  99 101 103]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 302: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  44  62  59  68  70  58  75  88  89  94  99 101 103]\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 303: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 103 104]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 304: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 103 104]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 305: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 103 104 105]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 306: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 103 104 105]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 307: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 104 105]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 308: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 309: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 310: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107]\n",
            "\n",
            "0: 384x640 15 persons, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 311: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 312: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 313: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107]\n",
            "\n",
            "0: 384x640 15 persons, 32.0ms\n",
            "Speed: 6.4ms preprocess, 32.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 314: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 7.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 315: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 316: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 317: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 13 persons, 27.7ms\n",
            "Speed: 3.8ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 318: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 319: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 320: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 321: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 322: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 323: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 324: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 325: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.7ms\n",
            "Speed: 3.6ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 326: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 327: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 7.0ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 328: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108 107]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 329: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108 107 111 112]\n",
            "\n",
            "0: 384x640 16 persons, 32.7ms\n",
            "Speed: 3.5ms preprocess, 32.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 330: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108 107 111 112]\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 331: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108 107 111 112]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 332: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 107 111 112 114 115]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 333: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 111 112 114 115 116]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 334: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 111 112 114 115 116]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 335: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 111 112 114 115 116 118]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 8.2ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 336: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 111 114 115 116 118]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 337: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 108 111 114 116 118 119]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 338: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 108 111 114 116 118 119 106 107]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 339: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 108 111 114 116 118 119 106 107]\n",
            "\n",
            "0: 384x640 16 persons, 26.9ms\n",
            "Speed: 3.6ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 340: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 108 111 114 116 119 106 107]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **log+speed**"
      ],
      "metadata": {
        "id": "PLpuCBXVbfqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from fpdf import FPDF  # Install with: pip install fpdf\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(\"yolov8m-pose.pt\")\n",
        "\n",
        "# Initialize annotators\n",
        "edge_annotator = sv.EdgeAnnotator()\n",
        "vertex_annotator = sv.VertexAnnotator()\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "trace_annotator = sv.TraceAnnotator()\n",
        "\n",
        "# Initialize tracker and smoother\n",
        "tracker = sv.ByteTrack()\n",
        "smoother = sv.DetectionsSmoother()\n",
        "\n",
        "# Dictionary to store previous positions and logs for each person\n",
        "previous_positions = {}\n",
        "people_logs = {}  # New dictionary to store logs per track_id\n",
        "\n",
        "# Get video properties (FPS)\n",
        "cap = cv2.VideoCapture(\"people-walking.mp4\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "cap.release()\n",
        "\n",
        "# Calibration factor (pixels per meter) - Adjust this based on your video!\n",
        "PIXELS_PER_METER = 100  # Example, refine as needed\n",
        "\n",
        "def calculate_speed(current_pos, prev_pos, fps, pixels_per_meter):\n",
        "    \"\"\"Calculate speed in meters per second.\"\"\"\n",
        "    distance_pixels = np.linalg.norm(current_pos - prev_pos)\n",
        "    distance_meters = distance_pixels / pixels_per_meter\n",
        "    time_interval = 1 / fps\n",
        "    speed = distance_meters / time_interval\n",
        "    return speed\n",
        "\n",
        "def log_to_pdf(track_id, log_data):\n",
        "    \"\"\"Generate a PDF log for a specific track_id.\"\"\"\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    pdf.cell(200, 10, txt=f\"Movement Log for Person ID {track_id}\", ln=True, align=\"C\")\n",
        "    pdf.cell(200, 10, txt=f\"Video FPS: {fps}\", ln=True)\n",
        "    pdf.ln(10)\n",
        "\n",
        "    # Table header\n",
        "    pdf.cell(40, 10, \"Frame\", border=1)\n",
        "    pdf.cell(40, 10, \"Time (s)\", border=1)\n",
        "    pdf.cell(50, 10, \"Position (x, y)\", border=1)\n",
        "    pdf.cell(40, 10, \"Speed (m/s)\", border=1)\n",
        "    pdf.ln()\n",
        "\n",
        "    # Table data\n",
        "    for entry in log_data:\n",
        "        frame, timestamp, pos_x, pos_y, speed = entry\n",
        "        pdf.cell(40, 10, str(frame), border=1)\n",
        "        pdf.cell(40, 10, f\"{timestamp:.2f}\", border=1)\n",
        "        pdf.cell(50, 10, f\"({pos_x:.1f}, {pos_y:.1f})\", border=1)\n",
        "        pdf.cell(40, 10, f\"{speed:.2f}\" if speed is not None else \"N/A\", border=1)\n",
        "        pdf.ln()\n",
        "\n",
        "    pdf.output(f\"log_person_{track_id}.pdf\")\n",
        "\n",
        "def callback(frame: np.ndarray, frame_idx: int) -> np.ndarray:\n",
        "    results = model(frame)[0]\n",
        "    key_points = sv.KeyPoints.from_ultralytics(results)\n",
        "    detections = key_points.as_detections()\n",
        "\n",
        "    detections = tracker.update_with_detections(detections)\n",
        "    detections = smoother.update_with_detections(detections)\n",
        "\n",
        "    # Debug output\n",
        "    print(f\"Frame {frame_idx}: detections type = {type(detections)}\")\n",
        "    if hasattr(detections, 'tracker_id'):\n",
        "        print(f\"Tracker IDs: {detections.tracker_id}\")\n",
        "    else:\n",
        "        print(\"No tracker_id attribute found in detections\")\n",
        "\n",
        "    # Annotate frame\n",
        "    annotated_frame = edge_annotator.annotate(frame.copy(), key_points=key_points)\n",
        "    annotated_frame = vertex_annotator.annotate(annotated_frame, key_points=key_points)\n",
        "    annotated_frame = box_annotator.annotate(annotated_frame, detections=detections)\n",
        "\n",
        "    # Process detections and log data\n",
        "    if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n",
        "        for i in range(len(detections.tracker_id)):\n",
        "            track_id = detections.tracker_id[i]\n",
        "            if track_id is None:\n",
        "                continue\n",
        "\n",
        "            x1, y1, x2, y2 = detections.xyxy[i]\n",
        "            current_pos = np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n",
        "            timestamp = frame_idx / fps  # Time in seconds\n",
        "\n",
        "            # Initialize log for new track_id\n",
        "            if track_id not in people_logs:\n",
        "                people_logs[track_id] = []\n",
        "\n",
        "            # Calculate speed if previous position exists\n",
        "            speed = None\n",
        "            if track_id in previous_positions and frame_idx > 0:\n",
        "                prev_pos = previous_positions[track_id]\n",
        "                speed = calculate_speed(current_pos, prev_pos, fps, PIXELS_PER_METER)\n",
        "\n",
        "                # Annotate speed on frame\n",
        "                label = f\"ID {track_id}: {speed:.2f} m/s\"\n",
        "                cv2.putText(\n",
        "                    annotated_frame,\n",
        "                    label,\n",
        "                    (int(x1), int(y1) - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5,\n",
        "                    (0, 255, 0),\n",
        "                    2,\n",
        "                )\n",
        "\n",
        "            # Log data: frame, timestamp, position, speed\n",
        "            people_logs[track_id].append((frame_idx, timestamp, current_pos[0], current_pos[1], speed))\n",
        "\n",
        "            # Update previous position\n",
        "            previous_positions[track_id] = current_pos\n",
        "    else:\n",
        "        print(\"Skipping speed calculation due to missing tracker_id\")\n",
        "\n",
        "    return trace_annotator.annotate(annotated_frame, detections=detections)\n",
        "\n",
        "# Process the video\n",
        "sv.process_video(\n",
        "    source_path=\"people-walking.mp4\",\n",
        "    target_path=\"result.mp4\",\n",
        "    callback=callback\n",
        ")\n",
        "\n",
        "# Generate PDF logs for each person after processing\n",
        "for track_id, log_data in people_logs.items():\n",
        "    log_to_pdf(track_id, log_data)\n",
        "\n",
        "print(\"PDF logs generated for each tracked person.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2OCr0S5W8U8",
        "outputId": "ba1c9f04-3d72-4021-dd37-e18201ebb8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 27.5ms\n",
            "Speed: 2.6ms preprocess, 27.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 0: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11]\n",
            "\n",
            "0: 384x640 15 persons, 23.4ms\n",
            "Speed: 3.8ms preprocess, 23.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 2: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12]\n",
            "\n",
            "0: 384x640 13 persons, 23.4ms\n",
            "Speed: 4.0ms preprocess, 23.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 3: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12]\n",
            "\n",
            "0: 384x640 11 persons, 23.5ms\n",
            "Speed: 3.9ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 4: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12]\n",
            "\n",
            "0: 384x640 11 persons, 23.5ms\n",
            "Speed: 4.1ms preprocess, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 5: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12]\n",
            "\n",
            "0: 384x640 12 persons, 23.4ms\n",
            "Speed: 4.1ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 6: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12 18]\n",
            "\n",
            "0: 384x640 13 persons, 23.5ms\n",
            "Speed: 3.4ms preprocess, 23.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 7: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 10 11 14 12 18]\n",
            "\n",
            "0: 384x640 14 persons, 23.4ms\n",
            "Speed: 3.3ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 8: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19]\n",
            "\n",
            "0: 384x640 13 persons, 23.4ms\n",
            "Speed: 3.4ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 9: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19]\n",
            "\n",
            "0: 384x640 13 persons, 23.4ms\n",
            "Speed: 3.8ms preprocess, 23.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 10: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19]\n",
            "\n",
            "0: 384x640 14 persons, 23.4ms\n",
            "Speed: 3.5ms preprocess, 23.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 11: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19]\n",
            "\n",
            "0: 384x640 14 persons, 23.4ms\n",
            "Speed: 3.7ms preprocess, 23.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 12: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19 21]\n",
            "\n",
            "0: 384x640 13 persons, 23.4ms\n",
            "Speed: 3.7ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 13: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8  9 11 14 12 18 19 21]\n",
            "\n",
            "0: 384x640 14 persons, 23.4ms\n",
            "Speed: 4.3ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 14: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10]\n",
            "\n",
            "0: 384x640 12 persons, 23.5ms\n",
            "Speed: 4.0ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 15: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10]\n",
            "\n",
            "0: 384x640 13 persons, 23.4ms\n",
            "Speed: 3.3ms preprocess, 23.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 16: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10  9]\n",
            "\n",
            "0: 384x640 14 persons, 23.5ms\n",
            "Speed: 4.7ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 17: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10  9]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 18: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 19 21 10  9]\n",
            "\n",
            "0: 384x640 13 persons, 24.9ms\n",
            "Speed: 4.6ms preprocess, 24.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 19: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 13 persons, 24.1ms\n",
            "Speed: 6.7ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 20: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 14 persons, 23.5ms\n",
            "Speed: 6.9ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 21: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 14 persons, 36.0ms\n",
            "Speed: 3.4ms preprocess, 36.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 22: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 23: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 24: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 28.5ms\n",
            "Speed: 3.4ms preprocess, 28.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 25: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 26: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 27: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 28: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 29: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 30: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 31: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 32: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 33: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 14 persons, 31.3ms\n",
            "Speed: 3.5ms preprocess, 31.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 34: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 27.7ms\n",
            "Speed: 3.4ms preprocess, 27.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 35: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 29.5ms\n",
            "Speed: 3.7ms preprocess, 29.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 36: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18  9 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 37: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 38: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 23 21]\n",
            "\n",
            "0: 384x640 13 persons, 28.7ms\n",
            "Speed: 6.1ms preprocess, 28.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 39: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 6.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 40: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 13 persons, 27.0ms\n",
            "Speed: 6.9ms preprocess, 27.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 41: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 5.5ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 42: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 2.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 43: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 44: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 45: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 46: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 47: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 48: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 49: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 50: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29]\n",
            "\n",
            "0: 384x640 15 persons, 28.2ms\n",
            "Speed: 4.4ms preprocess, 28.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 51: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 52: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 53: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 54: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31]\n",
            "\n",
            "0: 384x640 19 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 55: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 56: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32 33]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 57: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32 33]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 58: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32 33]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 59: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 31 23 32 33]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 60: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21  9 29 23 32 33]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 61: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  6  7  8 11 14 12 18 21 29 23 32 33]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 10.5ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 62: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 23 32 33]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 63: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 23 32 33]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 64: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 23 32]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 65: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 66: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35 36 33 23]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 67: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 68: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 69: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 35 36 33 23]\n",
            "\n",
            "0: 384x640 19 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 70: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 1  2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 71: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 19 persons, 26.6ms\n",
            "Speed: 5.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 72: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 73: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 74: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 33 23]\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 4.2ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 75: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 43 42]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 76: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 31 36 43 42 23 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 77: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 23 44]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 78: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 23 44]\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 79: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 23 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 80: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 23 44 31]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 81: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31]\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 82: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46]\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 83: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 84: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46]\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 85: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46]\n",
            "\n",
            "0: 384x640 18 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 86: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46 33]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 87: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 31 46 33]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 88: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 89: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 90: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 91: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 92: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 93: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 94: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 95: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 96: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 97: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 98: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 99: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 100: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 101: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 102: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 103: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 104: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 105: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 106: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 107: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 108: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 20 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 109: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 19 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 110: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7  8 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 111: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 112: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  4  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 113: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 114: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 115: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 116: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 117: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 118: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 119: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 120: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 17 persons, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 121: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 12 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 122: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 32 36 43 42 46 33 44]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 4.2ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 123: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 32 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 124: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 32 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 125: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 32 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 126: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 127: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  5  7 11 14 18 21 29 36 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 128: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 5.2ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 129: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  3  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 130: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 131: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 132: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 133: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 134: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 135: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 136: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 137: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 138: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2  7 11 14 18 21 29 43 42 46 33 44 56]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 139: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 18 21 29 43 42 46 33 44 56 32]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 140: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 18 21 29 43 42 46 33 44 56 32]\n",
            "\n",
            "0: 384x640 10 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 141: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 18 21 29 43 42 46 33 44 56 32  3]\n",
            "\n",
            "0: 384x640 8 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 142: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 32  3]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 143: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 32  3 18]\n",
            "\n",
            "0: 384x640 8 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 144: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 32  3 18]\n",
            "\n",
            "0: 384x640 11 persons, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 145: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56  3 18]\n",
            "\n",
            "0: 384x640 11 persons, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 146: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 147: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 148: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 149: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 150: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 11 persons, 29.6ms\n",
            "Speed: 3.8ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 151: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 13 persons, 32.5ms\n",
            "Speed: 4.3ms preprocess, 32.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 152: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 2.7ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 153: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 29 43 42 46 33 56 18 44 32  3 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 154: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 155: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 6.9ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 156: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 157: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 158: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44  3 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 6.0ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 159: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44 58 59]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 160: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 5.1ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 161: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59 44]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 162: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 53.6ms\n",
            "Speed: 12.3ms preprocess, 53.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 163: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 33.9ms\n",
            "Speed: 6.6ms preprocess, 33.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 164: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 59 44]\n",
            "\n",
            "0: 384x640 10 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 165: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44 61]\n",
            "\n",
            "0: 384x640 12 persons, 26.8ms\n",
            "Speed: 3.4ms preprocess, 26.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 166: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 44 61 59]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 167: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59]\n",
            "\n",
            "0: 384x640 12 persons, 27.3ms\n",
            "Speed: 3.5ms preprocess, 27.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 168: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59]\n",
            "\n",
            "0: 384x640 12 persons, 30.3ms\n",
            "Speed: 3.6ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 169: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59 44]\n",
            "\n",
            "0: 384x640 12 persons, 27.7ms\n",
            "Speed: 3.4ms preprocess, 27.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 170: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 171: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 172: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 59 44]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 173: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 174: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 175: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59]\n",
            "\n",
            "0: 384x640 12 persons, 26.7ms\n",
            "Speed: 3.7ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 176: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 177: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 178: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 179: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59 58]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 180: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 59 58]\n",
            "\n",
            "0: 384x640 12 persons, 27.0ms\n",
            "Speed: 4.1ms preprocess, 27.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 181: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 58]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 182: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 58]\n",
            "\n",
            "0: 384x640 11 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 183: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44 58]\n",
            "\n",
            "0: 384x640 10 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 184: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 185: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 18 61 44]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 186: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 187: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 188: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 189: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 190: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 27.7ms\n",
            "Speed: 3.4ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 191: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 192: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 193: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 194: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 195: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 196: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 197: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 198: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 199: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 200: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 6.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 201: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 202: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 203: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 204: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 205: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 42 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.7ms\n",
            "Speed: 6.9ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 206: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 207: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 208: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 209: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 13 persons, 28.1ms\n",
            "Speed: 5.7ms preprocess, 28.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 210: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 2 11 14 21 43 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 211: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 212: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 213: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 214: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 215: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 216: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 217: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 33 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 218: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 219: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 220: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 221: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 222: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 223: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 4.3ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 224: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 225: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 226: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 227: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 4.2ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 228: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 229: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 230: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75  2]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 231: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 232: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 233: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 234: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 235: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 236: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 237: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 238: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75 82]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 239: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [11 14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 240: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 241: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 242: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 243: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 244: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 245: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 246: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 247: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 5.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 248: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 43 46 56 61 44 62 59 68 70 58 76 75 82 83]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 249: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 82]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 250: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 82 85]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 251: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 85]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 252: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 85]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 253: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 85]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 254: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 85 88]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 255: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 256: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 257: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 258: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 259: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 260: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 261: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 262: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 263: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43 89]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 264: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 265: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 4.1ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 266: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 21 46 56 61 44 62 59 68 70 58 76 75 88 43 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 267: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 61 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 268: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 61 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 13 persons, 26.7ms\n",
            "Speed: 3.8ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 269: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 61 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 270: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 61 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 271: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 272: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 273: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 274: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 275: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 276: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 6.5ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 277: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 56 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 278: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 279: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 12 persons, 32.7ms\n",
            "Speed: 3.3ms preprocess, 32.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 280: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 6.0ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 281: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 282: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 92 94]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 283: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.8ms\n",
            "Speed: 3.8ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 284: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 285: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 286: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.8ms\n",
            "Speed: 3.5ms preprocess, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 287: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 76 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 288: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 289: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 290: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 291: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 292: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 27.4ms\n",
            "Speed: 3.6ms preprocess, 27.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 293: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 4.3ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 294: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 15 persons, 27.0ms\n",
            "Speed: 7.3ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 295: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 13 persons, 27.1ms\n",
            "Speed: 3.8ms preprocess, 27.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 296: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 15 persons, 30.4ms\n",
            "Speed: 3.4ms preprocess, 30.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 297: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 16 persons, 27.2ms\n",
            "Speed: 5.0ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 298: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 299: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [14 46 44 62 59 68 70 58 75 88 89 94 99]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 300: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  44  62  59  68  70  58  75  88  89  94  99 101]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 301: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  44  62  59  68  70  58  75  88  89  94  99 101 103]\n",
            "\n",
            "0: 384x640 14 persons, 27.6ms\n",
            "Speed: 8.5ms preprocess, 27.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 302: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  44  62  59  68  70  58  75  88  89  94  99 101 103]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 303: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 103 104]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 304: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 103 104]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.0ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 305: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 103 104 105]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 306: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 103 104 105]\n",
            "\n",
            "0: 384x640 11 persons, 26.7ms\n",
            "Speed: 3.5ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 307: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 104 105]\n",
            "\n",
            "0: 384x640 14 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 308: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 309: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106]\n",
            "\n",
            "0: 384x640 15 persons, 26.7ms\n",
            "Speed: 3.7ms preprocess, 26.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 310: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 311: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 312: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 313: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 314: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 315: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  94  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 316: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 4.8ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 317: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 6.1ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 318: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 12 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 319: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 320: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 321: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 14 persons, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 322: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  62  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 323: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 324: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 107 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 325: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 326: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 327: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 328: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108 107]\n",
            "\n",
            "0: 384x640 15 persons, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 329: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108 107 111 112]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 330: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108 107 111 112]\n",
            "\n",
            "0: 384x640 17 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 331: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  59  68  58  75  88  89  99 101 105 106 108 107 111 112]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 332: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 107 111 112 114 115]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 333: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 111 112 114 115 116]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 334: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 111 112 114 115 116]\n",
            "\n",
            "0: 384x640 15 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 335: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 111 112 114 115 116 118]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 336: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 106 108 111 114 115 116 118]\n",
            "\n",
            "0: 384x640 13 persons, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 337: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 108 111 114 116 118 119]\n",
            "\n",
            "0: 384x640 18 persons, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 338: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 108 111 114 116 118 119 106 107]\n",
            "\n",
            "0: 384x640 16 persons, 26.6ms\n",
            "Speed: 5.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 339: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 108 111 114 116 118 119 106 107]\n",
            "\n",
            "0: 384x640 16 persons, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 340: detections type = <class 'supervision.detection.core.Detections'>\n",
            "Tracker IDs: [ 14  46  68  58  75  88  89  99 101 105 108 111 114 116 119 106 107]\n",
            "PDF logs generated for each tracked person.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install FPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwSMMd3sZfkQ",
        "outputId": "5daa8981-8d6e-4127-ec9a-8675b662e07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting FPDF\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: FPDF\n",
            "  Building wheel for FPDF (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FPDF: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=3c86a4767bb35ba748f1c1b5f6049f44763248d709383ce63ef84d5f3f146f29\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built FPDF\n",
            "Installing collected packages: FPDF\n",
            "Successfully installed FPDF-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function MotionBasedMultiObjectTrackingExample()\n",
        "    % Setup system objects for video processing\n",
        "    obj = setupSystemObjects();\n",
        "    tracks = initializeTracks(); % Initialize an empty array of tracks\n",
        "    nextId = 1; % ID of the next track\n",
        "    logFile = fopen('tracking_log.txt', 'w'); % Open log file for writing\n",
        "\n",
        "    % Process each frame of the video\n",
        "    frameCount = 0;\n",
        "    while hasFrame(obj.reader)\n",
        "        frameCount = frameCount + 1;\n",
        "        frame = readFrame(obj.reader);\n",
        "        [centroids, bboxes, mask] = detectObjects(frame);\n",
        "        predictNewLocationsOfTracks();\n",
        "        [assignments, unassignedTracks, unassignedDetections] = ...\n",
        "            detectionToTrackAssignment();\n",
        "\n",
        "        updateAssignedTracks();\n",
        "        updateUnassignedTracks();\n",
        "        deleteLostTracks();\n",
        "        createNewTracks();\n",
        "\n",
        "        displayTrackingResults();\n",
        "        logTrackingResults(logFile, frameCount);\n",
        "    end\n",
        "\n",
        "    fclose(logFile); % Close the log file\n",
        "\n",
        "    % Nested functions for system setup and processing\n",
        "    function obj = setupSystemObjects()\n",
        "        obj.reader = VideoReader('people-walking.mp4');\n",
        "        obj.maskPlayer = vision.VideoPlayer('Position', [740, 400, 700, 400]);\n",
        "        obj.videoPlayer = vision.VideoPlayer('Position', [20, 400, 700, 400]);\n",
        "        obj.detector = vision.ForegroundDetector('NumGaussians', 3, ...\n",
        "            'NumTrainingFrames', 40, 'MinimumBackgroundRatio', 0.7);\n",
        "    end\n",
        "\n",
        "    function tracks = initializeTracks()\n",
        "        tracks = struct('id', {}, 'bbox', {}, 'kalmanFilter', {}, ...\n",
        "                        'age', {}, 'totalVisibleCount', {}, ...\n",
        "                        'consecutiveInvisibleCount', {});\n",
        "    end\n",
        "\n",
        "    function [centroids, bboxes, mask] = detectObjects(frame)\n",
        "        mask = obj.detector.step(frame);\n",
        "        mask = imopen(mask, strel('rectangle', [3,3]));\n",
        "        mask = imclose(mask, strel('rectangle', [15,15]));\n",
        "        mask = imfill(mask, 'holes');\n",
        "\n",
        "        stats = regionprops(mask, 'Centroid', 'BoundingBox');\n",
        "        centroids = cat(1, stats.Centroid);\n",
        "        bboxes = cat(1, stats.BoundingBox);\n",
        "    end\n",
        "\n",
        "    function predictNewLocationsOfTracks()\n",
        "        for i = 1:length(tracks)\n",
        "            bbox = tracks(i).bbox;\n",
        "            predictedCentroid = predict(tracks(i).kalmanFilter);\n",
        "            predictedCentroid = int32(predictedCentroid) - bbox(3:4) / 2;\n",
        "            tracks(i).bbox = [predictedCentroid, bbox(3:4)];\n",
        "        end\n",
        "    end\n",
        "\n",
        "    function updateAssignedTracks()\n",
        "        numAssignedTracks = size(assignments, 1);\n",
        "        for i = 1:numAssignedTracks\n",
        "            trackIdx = assignments(i, 1);\n",
        "            detectionIdx = assignments(i, 2);\n",
        "            centroid = centroids(detectionIdx, :);\n",
        "            bbox = bboxes(detectionIdx, :);\n",
        "\n",
        "            correct(tracks(trackIdx).kalmanFilter, centroid);\n",
        "\n",
        "            tracks(trackIdx).bbox = bbox;\n",
        "            tracks(trackIdx).age = tracks(trackIdx).age + 1;\n",
        "            tracks(trackIdx).totalVisibleCount = ...\n",
        "                tracks(trackIdx).totalVisibleCount + 1;\n",
        "            tracks(trackIdx).consecutiveInvisibleCount = 0;\n",
        "        end\n",
        "    end\n",
        "\n",
        "    function updateUnassignedTracks()\n",
        "        for i = 1:length(unassignedTracks)\n",
        "            ind = unassignedTracks(i);\n",
        "            tracks(ind).age = tracks(ind).age + 1;\n",
        "            tracks(ind).consecutiveInvisibleCount = ...\n",
        "                tracks(ind).consecutiveInvisibleCount + 1;\n",
        "        end\n",
        "    end\n",
        "\n",
        "    function deleteLostTracks()\n",
        "        if isempty(tracks)\n",
        "            return;\n",
        "        end\n",
        "\n",
        "        invisibleForTooLong = 20;\n",
        "        ageThreshold = 8;\n",
        "\n",
        "        ages = [tracks(:).age];\n",
        "        totalVisibleCounts = [tracks(:).totalVisibleCount];\n",
        "        visibility = totalVisibleCounts ./ ages;\n",
        "\n",
        "        lostInds = (ages < ageThreshold & visibility < 0.6) | ...\n",
        "                   [tracks(:).consecutiveInvisibleCount] >= invisibleForTooLong;\n",
        "\n",
        "        tracks = tracks(~lostInds);\n",
        "    end\n",
        "\n",
        "    function createNewTracks()\n",
        "        centroidsNewDetections = centroids(unassignedDetections, :);\n",
        "        bboxesNewDetections = bboxes(unassignedDetections, :);\n",
        "\n",
        "        for i = 1:size(centroidsNewDetections, 1)\n",
        "            centroidNewDetection = centroidsNewDetections(i,:);\n",
        "            bboxNewDetection = bboxesNewDetections(i,:);\n",
        "\n",
        "            kalmanFilterObj = configureKalmanFilter('ConstantVelocity', ...\n",
        "                centroidNewDetection, [200,50], [100,25], 100);\n",
        "\n",
        "            newTrackObj = struct('id', nextId, 'bbox', bboxNewDetection, ...\n",
        "                'kalmanFilter', kalmanFilterObj, 'age', 1, ...\n",
        "                'totalVisibleCount', 1, 'consecutiveInvisibleCount', 0);\n",
        "\n",
        "            tracks(end + 1) = newTrackObj; %#ok<AGROW>\n",
        "            nextId = nextId + 1;\n",
        "        end\n",
        "    end\n",
        "\n",
        "    function displayTrackingResults()\n",
        "        frameWithAnnotations = insertObjectAnnotation(frame, ...\n",
        "                                'rectangle', {tracks.bbox}, {tracks.id});\n",
        "\n",
        "        obj.videoPlayer.step(frameWithAnnotations);\n",
        "    end\n",
        "\n",
        "    function logTrackingResults(logFile, frameCount)\n",
        "        fprintf(logFile, 'Frame %d:\\n', frameCount);\n",
        "        for i = 1:length(tracks)\n",
        "            fprintf(logFile, '  - Object ID: %d, Bounding Box: [%d, %d, %d, %d], Age: %d\\n', ...\n",
        "                tracks(i).id, tracks(i).bbox(1), tracks(i).bbox(2), tracks(i).bbox(3), tracks(i).bbox(4), tracks(i).age);\n",
        "        end\n",
        "        fprintf(logFile, '\\n');\n",
        "    end\n",
        "end\n"
      ],
      "metadata": {
        "id": "Zbxx38u8ZiIK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "6f6f8f78-d23a-4b31-d34c-f99a2a584130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-4-868235138c7e>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-868235138c7e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    function MotionBasedMultiObjectTrackingExample()\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matlabengine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykyHxsMvjHfM",
        "outputId": "e4fc6563-6927-4012-e1ef-40018515362a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matlabengine\n",
            "  Using cached matlabengine-25.1.2.tar.gz (18 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: matlabengine\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for matlabengine \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for matlabengine (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for matlabengine\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build matlabengine\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (matlabengine)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wear-ZyAjRYD",
        "outputId": "1b9cbee5-586f-4037-875e-4c15855d07e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!python setup.py install --user"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr8xoyNJjSV-",
        "outputId": "277c7f66-f19f-44ea-ce38-a4ead2f4f708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matlab.engine\n",
        "eng = matlab.engine.start_matlab()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "ipBILkLIjIC3",
        "outputId": "cc28aee9-8b59-46f2-9ca3-b3c046dd9f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matlab'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9b17cde1df14>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_matlab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matlab'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find \"/content/drive/MyDrive/\" -name \"setup.py\" -exec du -sh {} \\;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8lwvKNnloOF",
        "outputId": "11b71c3e-9ffc-49a9-ab6b-db7eb3574438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/content/drive/MyDrive/’: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbGoEcIAlzib"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}